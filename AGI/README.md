# ğŸ§  Artificial General Intelligence (AGI)

AGI research aims to build systems that can **reason, learn, plan, generalize, and act across domains** â€” not just perform a single narrow task.

This part of the toolkit explains:
- What AGI actually means  
- The skills required to work toward AGI  
- Core AGI subfields  
- Research directions  
- Links to ML â†’ DL â†’ GenAI â†’ Agents â†’ AGI  
- Projects, tools & resources  
- Learning roadmap  

AGI is built on everything before it â€” **Machine Learning â†’ Deep Learning â†’ Transformers â†’ GenAI â†’ Agents â†’ AGI**.

---

# ğŸ§± Prerequisites

Before learning AGI, you must have a strong understanding of:

### ğŸ”¹ Required
- **Deep Learning** â†’ `../DeepLearning/README.md`
- **Transformers & LLMs** â†’ `../GenerativeAI/README.md`
- **Reinforcement Learning basics**
- **Math (linear algebra, probability, calculus)** â†’ `../Fundamentals/README.md`

### ğŸ”¹ Highly Recommended
- **Agents & tool use**
- **Multimodal DL (vision + text)**
- **Basic robotics knowledge (optional but helpful)** â†’ `../Robotics/README.md`

AGI sits at the **top of the intelligence hierarchy**.

---

# ğŸŒ 1. What is AGI?

AGI = Systems capable of:
- Autonomous decision-making  
- Long-horizon planning  
- Multi-step reasoning  
- Learning new skills  
- Operating across tasks & domains  
- Using tools  
- Building models of the world  
- Improving themselves over time  

AGI is **not** one algorithm.  
It is a **stack** of multiple AI capabilities connected together.

---

# ğŸ§© 2. Core AGI Subfields

### ğŸ”¹ **1. Multimodal Deep Learning**
Models that understand:
- Vision  
- Text  
- Audio  
- Video  
- Actions  

Examples:  
CLIP, GPT-4o, Flamingo, LLaVA, Kosmos-2  

---

### ğŸ”¹ **2. Large Language Models & Reasoning**
- Transformers  
- Long-context models  
- Chain-of-Thought reasoning  
- Program synthesis  
- Tool use  
- Planning  

LLMs form the **reasoning core** of modern proto-AGI systems.

---

### ğŸ”¹ **3. Reinforcement Learning (CRITICAL)**
- RLHF  
- PPO / A2C / SAC  
- Hierarchical RL  
- World models (MuZero-style)  
- Agency & reward modeling  

RL is essential for **autonomous behavior**, not just text generation.

---

### ğŸ”¹ **4. Agents & Tool Use**
Agents are LLMs that:
- Use tools  
- Plan steps  
- Query memory  
- Execute functions  
- Adapt based on feedback  

Frameworks:  
LangGraph, SmolAgents, OpenDevin, AutoGPT, Voyager

---

### ğŸ”¹ **5. Cognitive Architectures**
Inspired by:
- Human memory  
- Reasoning  
- Working memory  
- Planning & symbolic logic  

Hybrid neural-symbolic systems belong here.

---

### ğŸ”¹ **6. Continual & Lifelong Learning**
- Avoiding catastrophic forgetting  
- Curriculum learning  
- Adaptive memory  
- Meta-learning  

An AGI must learn **continuously**, not freeze after training.

---

### ğŸ”¹ **7. World Models**
Systems that build internal models of:
- The environment  
- Cause & effect  
- Spatial and temporal structure  
- Future prediction  

Examples:  
Dreamer, MuZero, VideoGPT, latent-

