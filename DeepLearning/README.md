# üî• Deep Learning

Deep Learning is the **core engine** behind modern AI ‚Äî powering vision, NLP, robotics, autonomous systems, and especially Generative AI.

This section covers:
- Neural networks  
- CNNs, RNNs, LSTMs  
- Transformers (foundation of GenAI)  
- Vision & NLP basics  
- Projects  
- Resources  
- What to learn before & after  

---

# üß± Prerequisites

Before starting Deep Learning, you must complete:

- **Machine Learning** ‚Üí `../MachineLearning/README.md`
- **Python** ‚Üí `../Fundamentals/README.md#1-python`
- **Math (Calculus, Linear Algebra)** ‚Üí `../Fundamentals/README.md#2-mathematics-for-ai`
- **Pandas, NumPy, EDA** ‚Üí `../Fundamentals/README.md#3-data-science-essentials`

These are mandatory for understanding DL training loops, tensors, and gradients.

---

# üß† 1. Deep Learning Core Learning Path

| Topic | Description | Link |
|-------|-------------|------|
| 100 Days of DL | Full DL roadmap using PyTorch <br><small>Beginner ‚Üí Advanced</small> | ‚ñ∂Ô∏è [Link](https://youtube.com/playlist?list=PLKnIA16_RmvYuZauWaPlRTC54KxSNLtNn) |
| PyTorch Full Tutorial | Tensors, autograd, training loops <br><small>Build models from scratch</small> | ‚ñ∂Ô∏è [Link](https://youtube.com/playlist?list=PLKnIA16_Rmvboy8bmDCjwNHgTaYH2puK7) |
| Neural Nets from Scratch | Math + implementation of neural networks <br><small>Strong fundamentals</small> | ‚ñ∂Ô∏è [Link](https://youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ) |
| DL Visual Intuition | Visual explanation of neural networks <br><small>Perfect before CNNs</small> | ‚ñ∂Ô∏è [Link](https://youtu.be/aircAruvnKk) |

---

# üß¨ 2. Deep Learning Subtopics

### üîπ Neural Networks (core)
- Perceptrons  
- Feed-forward networks  
- Activation functions  
- Loss functions  
- Optimization (SGD, Adam)  
- Backpropagation  

### üîπ Convolutional Neural Networks (Vision)
- Feature extraction  
- Filters, kernels, strides  
- CNN architectures: LeNet, VGG, ResNet  
- Object detection (YOLO, SSD)  
- Segmentation (UNet, Mask R-CNN)

### üîπ Recurrent Neural Networks (Sequence Models)
- RNN fundamentals  
- LSTMs & GRUs  
- Sequence prediction  
- Time-series modeling  

### üîπ Transformers (MOST important)
- Attention mechanism  
- Encoder‚Äìdecoder  
- Positional encoding  
- Self-attention  
- Multi-head attention  
*This is the foundation for GenAI & LLMs.*

---

# ü§ñ 3. Transformers & LLM Foundations

| Topic | Description | Link |
|-------|-------------|------|
| Transformers Explained | Core architecture breakdown <br><small>Attention made simple</small> | ‚ñ∂Ô∏è [Link](https://youtu.be/8fX3rOjTloc) |
| Intro to LLMs | What LLMs are & how they work <br><small>Beginner-friendly</small> | ‚ñ∂Ô∏è [Link](https://youtu.be/zjkBMFhNj_g) |
| LLM Deep Dive | Scaling laws, architecture, training <br><small>Advanced understanding</small> | ‚ñ∂Ô∏è [Link](https://youtu.be/7xTGNNLPyMI) |
| Fine-Tuning Models | LoRA, PEFT, QLoRA <br><small>Hands-on tutorial</small> | ‚ñ∂Ô∏è [Link](https://youtu.be/eC6Hd1hFvos) |
| Transformers Simplified | Easiest transformer explanation <br><small>Great for beginners</small> | ‚ñ∂Ô∏è [Link](https://youtu.be/ZhAz268Hdpw) |
| Attention Explained | Theory behind attention <br><small>Intuitive explanation</small> | ‚ñ∂Ô∏è [Link](https://youtu.be/wjZofJX0v4M) |

---

# üõ† 4. Deep Learning Projects

| Topic | Description | Link |
|-------|-------------|------|
| DL Projects Playlist | Vision, NLP, audio,

